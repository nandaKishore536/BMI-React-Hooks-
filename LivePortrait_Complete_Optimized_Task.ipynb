{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandaKishore536/BMI-React-Hooks-/blob/main/LivePortrait_Complete_Optimized_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "31ae84fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ae84fc",
        "outputId": "3344f853-8c60-4005-d340-811530870b4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LivePortrait' already exists and is not an empty directory.\n",
            "/content/LivePortrait\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: pyyaml==6.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: opencv-python==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 3)) (4.10.0.84)\n",
            "Requirement already satisfied: scipy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: imageio==2.34.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 5)) (2.34.2)\n",
            "Requirement already satisfied: lmdb==1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 7)) (4.66.4)\n",
            "Requirement already satisfied: rich==13.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 8)) (13.7.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: onnx==1.16.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 10)) (1.16.1)\n",
            "Requirement already satisfied: scikit-image==0.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 11)) (0.24.0)\n",
            "Requirement already satisfied: albumentations==1.4.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 12)) (1.4.10)\n",
            "Requirement already satisfied: matplotlib==3.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 13)) (3.9.0)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 14)) (0.5.1)\n",
            "Requirement already satisfied: tyro==0.8.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 15)) (0.8.5)\n",
            "Requirement already satisfied: gradio==5.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 16)) (5.1.0)\n",
            "Requirement already satisfied: pykalman==0.9.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 17)) (0.9.7)\n",
            "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements_base.txt (line 18)) (10.4.0)\n",
            "Requirement already satisfied: onnxruntime-gpu==1.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.18.0)\n",
            "Requirement already satisfied: transformers==4.38.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.38.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->-r requirements_base.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1->-r requirements_base.txt (line 8)) (2.19.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python==0.2.0->-r requirements_base.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx==1.16.1->-r requirements_base.txt (line 10)) (5.29.5)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (2025.5.26)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image==0.24.0->-r requirements_base.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (4.13.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (1.6.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (2.11.5)\n",
            "Requirement already satisfied: albucore>=0.0.11 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->-r requirements_base.txt (line 12)) (4.11.0.86)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.0->-r requirements_base.txt (line 13)) (2.9.0.post0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from imageio-ffmpeg==0.5.1->-r requirements_base.txt (line 14)) (75.2.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro==0.8.5->-r requirements_base.txt (line 15)) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro==0.8.5->-r requirements_base.txt (line 15)) (1.7.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.32.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (2.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.11.12)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.1.0->-r requirements_base.txt (line 16)) (0.34.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.0->-r requirements.txt (line 4)) (0.5.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (2025.3.2)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (12.0)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore>=0.0.11->albumentations==1.4.10->-r requirements_base.txt (line 12)) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore>=0.0.11->albumentations==1.4.10->-r requirements_base.txt (line 12)) (6.2.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (0.46.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.1.0->-r requirements_base.txt (line 16)) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.1.0->-r requirements_base.txt (line 16)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.1.0->-r requirements_base.txt (line 16)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio==5.1.0->-r requirements_base.txt (line 16)) (1.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->-r requirements_base.txt (line 8)) (0.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.1.0->-r requirements_base.txt (line 16)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->-r requirements_base.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->-r requirements_base.txt (line 12)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->-r requirements_base.txt (line 12)) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.0->-r requirements_base.txt (line 13)) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->-r requirements_base.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->-r requirements_base.txt (line 12)) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.1.0->-r requirements_base.txt (line 16)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.1.0->-r requirements_base.txt (line 16)) (1.5.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.0->-r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu==1.18.0->-r requirements.txt (line 3)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/KwaiVGI/LivePortrait.git\n",
        "%cd LivePortrait\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6a4a8fee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a4a8fee",
        "outputId": "b34690fd-6e0c-450e-a7c1-4200992f60b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install git-lfs\n",
        "!git lfs install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e9d7ab2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e9d7ab2",
        "outputId": "75f16a67-9209-41e0-ecc6-686714843837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temp_pretrained_weights'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 90 (delta 3), reused 0 (delta 0), pack-reused 76 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (90/90), 23.59 KiB | 259.00 KiB/s, done.\n",
            "Filtering content: 100% (20/20), 1.99 GiB | 68.46 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/KwaiVGI/LivePortrait temp_pretrained_weights\n",
        "!mkdir -p pretrained_weights\n",
        "!mv temp_pretrained_weights/* pretrained_weights/\n",
        "!rm -rf temp_pretrained_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1178c557",
      "metadata": {
        "id": "1178c557"
      },
      "source": [
        "**Upload Photo in jpg formate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6de0d053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6de0d053",
        "outputId": "1ab473f2-e561-49d5-adfd-afcdd7f866bf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85bbe5dd-cd8c-4002-911a-75d617177e16\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85bbe5dd-cd8c-4002-911a-75d617177e16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving s7.jpg to s7.jpg\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f616a1e",
      "metadata": {
        "id": "1f616a1e"
      },
      "source": [
        "**Upload the Video in Mp4 formate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "424fd590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "424fd590",
        "outputId": "e648764d-7c98-4657-c498-e28cf9feac23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b6cf273-6331-4ce4-aff8-bce64757682e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b6cf273-6331-4ce4-aff8-bce64757682e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving d19.mp4 to d19.mp4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e4eb9827",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4eb9827",
        "outputId": "80d1942b-ebbc-46d4-f0d5-e58724ea29da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[07:07:03]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor from    \u001b]8;id=655166;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=325066;file:///content/LivePortrait/src/live_portrait_wrapper.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mappearance_featu\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mre_extractor.pth\u001b[0m done.                    \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[07:07:04]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor from                \u001b]8;id=654338;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=897922;file:///content/LivePortrait/src/live_portrait_wrapper.py#49\u001b\\\u001b[2m49\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mmotion_extractor\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95m.pth\u001b[0m done.                                \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad warping_module from                  \u001b]8;id=503541;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=999158;file:///content/LivePortrait/src/live_portrait_wrapper.py#52\u001b\\\u001b[2m52\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mwarping_module.p\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mth\u001b[0m done.                                  \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[07:07:05]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator from                 \u001b]8;id=126985;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625061;file:///content/LivePortrait/src/live_portrait_wrapper.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mspade_generator.\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mpth\u001b[0m done.                                 \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module from    \u001b]8;id=271903;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=709582;file:///content/LivePortrait/src/live_portrait_wrapper.py#59\u001b\\\u001b[2m59\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/retargeting_models/\u001b[0m\u001b[95mstitching\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95m_retargeting_module.pth\u001b[0m done.             \u001b[2m                           \u001b[0m\n",
            "\u001b[1;31m2025-06-04 07:07:05.587827288 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[1;31m2025-06-04 07:07:05.649788169 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m238s           \u001b]8;id=197462;file:///content/LivePortrait/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=601351;file:///content/LivePortrait/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[1;31m2025-06-04 07:07:05.991195792 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m[07:07:06]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m119s        \u001b]8;id=714878;file:///content/LivePortrait/src/utils/human_landmark_runner.py\u001b\\\u001b[2mhuman_landmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=718810;file:///content/LivePortrait/src/utils/human_landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad source image from s7.jpg            \u001b]8;id=557603;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=131576;file:///content/LivePortrait/src/live_portrait_pipeline.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad driving video from: d19.mp4, FPS   \u001b]8;id=503523;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=260195;file:///content/LivePortrait/src/live_portrait_pipeline.py#133\u001b\\\u001b[2m133\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mis \u001b[1;36m30\u001b[0m                                   \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mStart making driving motion template\u001b[33m...\u001b[0m \u001b]8;id=750945;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=495287;file:///content/LivePortrait/src/live_portrait_pipeline.py#144\u001b\\\u001b[2m144\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2KMaking motion templates... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25h\u001b[2;36m[07:07:57]\u001b[0m\u001b[2;36m \u001b[0mDump motion template to d19.pkl         \u001b]8;id=328083;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=278936;file:///content/LivePortrait/src/live_portrait_pipeline.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mPrepared pasteback mask done.           \u001b]8;id=870943;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=223553;file:///content/LivePortrait/src/live_portrait_pipeline.py#183\u001b\\\u001b[2m183\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m[07:07:59]\u001b[0m\u001b[2;36m \u001b[0mThe animated video consists of \u001b[1;36m250\u001b[0m      \u001b]8;id=376612;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=586927;file:///content/LivePortrait/src/live_portrait_pipeline.py#270\u001b\\\u001b[2m270\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mframes.                                 \u001b[2m                             \u001b[0m\n",
            "\u001b[2K🚀Animating... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:37\u001b[0m\n",
            "\u001b[2KConcatenating result... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:07\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[2;36m[07:08:45]\u001b[0m\u001b[2;36m \u001b[0mAudio is selected from d19.mp4, concat  \u001b]8;id=557495;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=285993;file:///content/LivePortrait/src/live_portrait_pipeline.py#480\u001b\\\u001b[2m480\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mmode                                    \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m[07:08:46]\u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                 \u001b]8;id=493012;file:///content/LivePortrait/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=819989;file:///content/LivePortrait/src/utils/video.py#204\u001b\\\u001b[2m204\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat_with_audio.mp4\u001b[0m                   \u001b[2m            \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mReplace                                 \u001b]8;id=412833;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=948714;file:///content/LivePortrait/src/live_portrait_pipeline.py#483\u001b\\\u001b[2m483\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat_with_audio.mp4\u001b[0m  \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0mwith .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat.mp4\u001b[0m        \u001b[2m                             \u001b[0m\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\u001b[1;34m[swscaler @ 0x253750c0] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:07\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[2;36m[07:08:55]\u001b[0m\u001b[2;36m \u001b[0mAudio is selected from d19.mp4          \u001b]8;id=247218;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=310314;file:///content/LivePortrait/src/live_portrait_pipeline.py#496\u001b\\\u001b[2m496\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                 \u001b]8;id=668655;file:///content/LivePortrait/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=700862;file:///content/LivePortrait/src/utils/video.py#204\u001b\\\u001b[2m204\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_with_audio.mp4\u001b[0m                          \u001b[2m            \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mReplace .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_with_audio.mp4\u001b[0m \u001b]8;id=267359;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=85446;file:///content/LivePortrait/src/live_portrait_pipeline.py#499\u001b\\\u001b[2m499\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mwith .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19.mp4\u001b[0m               \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;32mAnimated template: d19.pkl, you can    \u001b[0m \u001b]8;id=239763;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=525357;file:///content/LivePortrait/src/live_portrait_pipeline.py#503\u001b\\\u001b[2m503\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mspecify `-d` argument with this        \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mtemplate path next time to avoid       \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mcropping video, motion making and      \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mprotecting privacy.                    \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video: .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19.mp4\u001b[0m    \u001b]8;id=882687;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=489460;file:///content/LivePortrait/src/live_portrait_pipeline.py#504\u001b\\\u001b[2m504\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video with concat:             \u001b]8;id=725965;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=500282;file:///content/LivePortrait/src/live_portrait_pipeline.py#505\u001b\\\u001b[2m505\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat.mp4\u001b[0m             \u001b[2m                             \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/LivePortrait/inference.py --source s7.jpg --driving d19.mp4 --output-dir ./output/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4220525a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4220525a",
        "outputId": "5058e4d0-7ce5-4d15-b22b-54fe6c580560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[07:09:17]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor from    \u001b]8;id=14535;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=19956;file:///content/LivePortrait/src/live_portrait_wrapper.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mappearance_featu\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mre_extractor.pth\u001b[0m done.                    \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor from                \u001b]8;id=884818;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=274461;file:///content/LivePortrait/src/live_portrait_wrapper.py#49\u001b\\\u001b[2m49\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mmotion_extractor\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95m.pth\u001b[0m done.                                \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[07:09:18]\u001b[0m\u001b[2;36m \u001b[0mLoad warping_module from                  \u001b]8;id=415391;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=197393;file:///content/LivePortrait/src/live_portrait_wrapper.py#52\u001b\\\u001b[2m52\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mwarping_module.p\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mth\u001b[0m done.                                  \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[07:09:19]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator from                 \u001b]8;id=835723;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341485;file:///content/LivePortrait/src/live_portrait_wrapper.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mspade_generator.\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mpth\u001b[0m done.                                 \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module from    \u001b]8;id=308296;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=252596;file:///content/LivePortrait/src/live_portrait_wrapper.py#59\u001b\\\u001b[2m59\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/retargeting_models/\u001b[0m\u001b[95mstitching\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95m_retargeting_module.pth\u001b[0m done.             \u001b[2m                           \u001b[0m\n",
            "\u001b[1;31m2025-06-04 07:09:19.193130396 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[1;31m2025-06-04 07:09:19.232835270 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m353s           \u001b]8;id=215244;file:///content/LivePortrait/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=764650;file:///content/LivePortrait/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[1;31m2025-06-04 07:09:20.143905233 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m[07:09:20]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m121s        \u001b]8;id=586757;file:///content/LivePortrait/src/utils/human_landmark_runner.py\u001b\\\u001b[2mhuman_landmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=992227;file:///content/LivePortrait/src/utils/human_landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad source image from s7.jpg            \u001b]8;id=889428;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=323858;file:///content/LivePortrait/src/live_portrait_pipeline.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad driving video from: d19.mp4, FPS   \u001b]8;id=702950;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=44936;file:///content/LivePortrait/src/live_portrait_pipeline.py#133\u001b\\\u001b[2m133\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mis \u001b[1;36m30\u001b[0m                                   \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mStart making driving motion template\u001b[33m...\u001b[0m \u001b]8;id=14716;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=56472;file:///content/LivePortrait/src/live_portrait_pipeline.py#144\u001b\\\u001b[2m144\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2KMaking motion templates... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25h\u001b[2;36m[07:10:09]\u001b[0m\u001b[2;36m \u001b[0mDump motion template to d19.pkl         \u001b]8;id=930793;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826172;file:///content/LivePortrait/src/live_portrait_pipeline.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mPrepared pasteback mask done.           \u001b]8;id=116763;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=542695;file:///content/LivePortrait/src/live_portrait_pipeline.py#183\u001b\\\u001b[2m183\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m[07:10:11]\u001b[0m\u001b[2;36m \u001b[0mThe animated video consists of \u001b[1;36m250\u001b[0m      \u001b]8;id=259778;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=725269;file:///content/LivePortrait/src/live_portrait_pipeline.py#270\u001b\\\u001b[2m270\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mframes.                                 \u001b[2m                             \u001b[0m\n",
            "\u001b[2K🚀Animating... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:37\u001b[0m\n",
            "\u001b[2KConcatenating result... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:06\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[2;36m[07:10:56]\u001b[0m\u001b[2;36m \u001b[0mAudio is selected from d19.mp4, concat  \u001b]8;id=476456;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=491081;file:///content/LivePortrait/src/live_portrait_pipeline.py#480\u001b\\\u001b[2m480\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mmode                                    \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m[07:10:57]\u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                 \u001b]8;id=805981;file:///content/LivePortrait/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=235837;file:///content/LivePortrait/src/utils/video.py#204\u001b\\\u001b[2m204\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat_with_audio.mp4\u001b[0m                   \u001b[2m            \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mReplace                                 \u001b]8;id=765537;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=707300;file:///content/LivePortrait/src/live_portrait_pipeline.py#483\u001b\\\u001b[2m483\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat_with_audio.mp4\u001b[0m  \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0mwith .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat.mp4\u001b[0m        \u001b[2m                             \u001b[0m\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\u001b[1;34m[swscaler @ 0x98930c0] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[2;36m[07:11:06]\u001b[0m\u001b[2;36m \u001b[0mAudio is selected from d19.mp4          \u001b]8;id=620239;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=931186;file:///content/LivePortrait/src/live_portrait_pipeline.py#496\u001b\\\u001b[2m496\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                 \u001b]8;id=453615;file:///content/LivePortrait/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=316192;file:///content/LivePortrait/src/utils/video.py#204\u001b\\\u001b[2m204\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_with_audio.mp4\u001b[0m                          \u001b[2m            \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mReplace .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_with_audio.mp4\u001b[0m \u001b]8;id=294919;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=690393;file:///content/LivePortrait/src/live_portrait_pipeline.py#499\u001b\\\u001b[2m499\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mwith .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19.mp4\u001b[0m               \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;32mAnimated template: d19.pkl, you can    \u001b[0m \u001b]8;id=502786;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=615928;file:///content/LivePortrait/src/live_portrait_pipeline.py#503\u001b\\\u001b[2m503\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mspecify `-d` argument with this        \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mtemplate path next time to avoid       \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mcropping video, motion making and      \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mprotecting privacy.                    \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video: .\u001b[35m/output/\u001b[0m\u001b[95ms7--d19.mp4\u001b[0m    \u001b]8;id=922816;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=955493;file:///content/LivePortrait/src/live_portrait_pipeline.py#504\u001b\\\u001b[2m504\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video with concat:             \u001b]8;id=961019;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=80059;file:///content/LivePortrait/src/live_portrait_pipeline.py#505\u001b\\\u001b[2m505\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output/\u001b[0m\u001b[95ms7--d19_concat.mp4\u001b[0m             \u001b[2m                             \u001b[0m\n",
            "⏱ Inference Time: 112.89 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "!python /content/LivePortrait/inference.py --source s7.jpg --driving d19.mp4 --output-dir ./output/\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"⏱ Inference Time:\", round(end_time - start_time, 2), \"seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0b589af",
      "metadata": {
        "id": "e0b589af"
      },
      "source": [
        "**We can download the ouput file in mp4 formate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8f74cd83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8f74cd83",
        "outputId": "72a3d85e-1806-49ef-d43c-a38a2cfdff99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2096e022-5752-48c5-8cc0-2f66f5d61f08\", \"s7--d19.mp4\", 920493)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_84d4e31a-1351-4bcb-a409-9fdfba571eff\", \"s7--d19_concat.mp4\", 810891)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('./output/s7--d19.mp4')\n",
        "files.download('./output/s7--d19_concat.mp4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d8167c",
      "metadata": {
        "id": "24d8167c"
      },
      "source": [
        "## FP16 Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fc5611e7",
      "metadata": {
        "id": "fc5611e7"
      },
      "outputs": [],
      "source": [
        "# Inject FP16 conversion into model loading for optimization\n",
        "!sed -i \"/model.load_state_dict/a\\    model = model.half()\" /content/LivePortrait/src/live_portrait_wrapper.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "818b66b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "818b66b9",
        "outputId": "9eea52b8-6ee4-457f-e352-f8805e319ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[07:14:51]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor from    \u001b]8;id=16415;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=85813;file:///content/LivePortrait/src/live_portrait_wrapper.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mappearance_featu\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mre_extractor.pth\u001b[0m done.                    \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[07:14:52]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor from                \u001b]8;id=12048;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=277507;file:///content/LivePortrait/src/live_portrait_wrapper.py#49\u001b\\\u001b[2m49\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mmotion_extractor\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95m.pth\u001b[0m done.                                \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad warping_module from                  \u001b]8;id=514396;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703291;file:///content/LivePortrait/src/live_portrait_wrapper.py#52\u001b\\\u001b[2m52\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mwarping_module.p\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mth\u001b[0m done.                                  \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m[07:14:53]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator from                 \u001b]8;id=996745;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=313721;file:///content/LivePortrait/src/live_portrait_wrapper.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/base_models/\u001b[0m\u001b[95mspade_generator.\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95mpth\u001b[0m done.                                 \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module from    \u001b]8;id=314673;file:///content/LivePortrait/src/live_portrait_wrapper.py\u001b\\\u001b[2mlive_portrait_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=54953;file:///content/LivePortrait/src/live_portrait_wrapper.py#59\u001b\\\u001b[2m59\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/LivePortrait/pretrained_weights/\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mliveportrait/retargeting_models/\u001b[0m\u001b[95mstitching\u001b[0m \u001b[2m                           \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95m_retargeting_module.pth\u001b[0m done.             \u001b[2m                           \u001b[0m\n",
            "\u001b[1;31m2025-06-04 07:14:53.462586449 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[1;31m2025-06-04 07:14:53.489632190 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m219s           \u001b]8;id=530519;file:///content/LivePortrait/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=564388;file:///content/LivePortrait/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[1;31m2025-06-04 07:14:53.815908864 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m[07:14:54]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m123s        \u001b]8;id=676755;file:///content/LivePortrait/src/utils/human_landmark_runner.py\u001b\\\u001b[2mhuman_landmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=234874;file:///content/LivePortrait/src/utils/human_landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad source image from s7.jpg            \u001b]8;id=742293;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=3980;file:///content/LivePortrait/src/live_portrait_pipeline.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad driving video from: d19.mp4, FPS   \u001b]8;id=479232;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=74927;file:///content/LivePortrait/src/live_portrait_pipeline.py#133\u001b\\\u001b[2m133\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mis \u001b[1;36m30\u001b[0m                                   \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mStart making driving motion template\u001b[33m...\u001b[0m \u001b]8;id=634098;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=149536;file:///content/LivePortrait/src/live_portrait_pipeline.py#144\u001b\\\u001b[2m144\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2KMaking motion templates... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25h\u001b[2;36m[07:15:43]\u001b[0m\u001b[2;36m \u001b[0mDump motion template to d19.pkl         \u001b]8;id=884400;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=717828;file:///content/LivePortrait/src/live_portrait_pipeline.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mPrepared pasteback mask done.           \u001b]8;id=63501;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=964708;file:///content/LivePortrait/src/live_portrait_pipeline.py#183\u001b\\\u001b[2m183\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m[07:15:44]\u001b[0m\u001b[2;36m \u001b[0mThe animated video consists of \u001b[1;36m250\u001b[0m      \u001b]8;id=69916;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=635468;file:///content/LivePortrait/src/live_portrait_pipeline.py#270\u001b\\\u001b[2m270\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mframes.                                 \u001b[2m                             \u001b[0m\n",
            "\u001b[2K🚀Animating... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:38\u001b[0m\n",
            "\u001b[2KConcatenating result... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:07\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[2;36m[07:16:32]\u001b[0m\u001b[2;36m \u001b[0mAudio is selected from d19.mp4, concat  \u001b]8;id=679728;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=349561;file:///content/LivePortrait/src/live_portrait_pipeline.py#480\u001b\\\u001b[2m480\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0mmode                                    \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                 \u001b]8;id=24131;file:///content/LivePortrait/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=693127;file:///content/LivePortrait/src/utils/video.py#204\u001b\\\u001b[2m204\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19_concat_with_audio.mp4\u001b[0m              \u001b[2m            \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mReplace                                 \u001b]8;id=166872;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=74231;file:///content/LivePortrait/src/live_portrait_pipeline.py#483\u001b\\\u001b[2m483\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19_concat_with_audio\u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95m.mp4\u001b[0m with                               \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19_concat.mp4\u001b[0m        \u001b[2m                             \u001b[0m\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\u001b[1;34m[swscaler @ 0x3174e0c0] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[2KWriting \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:07\u001b[0m\n",
            "\u001b[1A\u001b[2K\u001b[2;36m[07:16:40]\u001b[0m\u001b[2;36m \u001b[0mAudio is selected from d19.mp4          \u001b]8;id=414946;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=498096;file:///content/LivePortrait/src/live_portrait_pipeline.py#496\u001b\\\u001b[2m496\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                 \u001b]8;id=656100;file:///content/LivePortrait/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=871873;file:///content/LivePortrait/src/utils/video.py#204\u001b\\\u001b[2m204\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19_with_audio.mp4\u001b[0m                     \u001b[2m            \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mReplace                                 \u001b]8;id=588703;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=984494;file:///content/LivePortrait/src/live_portrait_pipeline.py#499\u001b\\\u001b[2m499\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19_with_audio.mp4\u001b[0m    \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0mwith .\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19.mp4\u001b[0m          \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;32mAnimated template: d19.pkl, you can    \u001b[0m \u001b]8;id=402261;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=298837;file:///content/LivePortrait/src/live_portrait_pipeline.py#503\u001b\\\u001b[2m503\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mspecify `-d` argument with this        \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mtemplate path next time to avoid       \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mcropping video, motion making and      \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[1;32mprotecting privacy.                    \u001b[0m \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video:                         \u001b]8;id=711694;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=13238;file:///content/LivePortrait/src/live_portrait_pipeline.py#504\u001b\\\u001b[2m504\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19.mp4\u001b[0m               \u001b[2m                             \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mAnimated video with concat:             \u001b]8;id=856496;file:///content/LivePortrait/src/live_portrait_pipeline.py\u001b\\\u001b[2mlive_portrait_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=955367;file:///content/LivePortrait/src/live_portrait_pipeline.py#505\u001b\\\u001b[2m505\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m.\u001b[35m/output_fp16/\u001b[0m\u001b[95ms7--d19_concat.mp4\u001b[0m        \u001b[2m                             \u001b[0m\n",
            "⏱ Optimized Inference Time (FP16): 112.23 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Run optimized inference (FP16)\n",
        "!python /content/LivePortrait/inference.py --source s7.jpg --driving d19.mp4 --output-dir ./output_fp16/\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"⏱ Optimized Inference Time (FP16):\", round(end_time - start_time, 2), \"seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example (if you saved times in variables):\n",
        "baseline_time = 15.2  # replace with actual\n",
        "fp16_time = 8.1       # replace with actual\n",
        "\n",
        "print(f\" Baseline Inference Time: {baseline_time} sec\")\n",
        "print(f\" FP16 Inference Time: {fp16_time} sec\")\n",
        "print(f\" Speedup: {round((baseline_time - fp16_time) / baseline_time * 100, 2)}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT79CurK0FrD",
        "outputId": "602655c5-3c03-44b0-8ceb-e2f91ac48657"
      },
      "id": "YT79CurK0FrD",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Baseline Inference Time: 15.2 sec\n",
            " FP16 Inference Time: 8.1 sec\n",
            " Speedup: 46.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5s9QSR-Z1Uu-"
      },
      "id": "5s9QSR-Z1Uu-",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2e326de9",
      "metadata": {
        "id": "2e326de9"
      },
      "source": [
        "## Comparison Summary\n",
        "\n",
        "- **Baseline Inference Time:** (as printed above from cell 8)\n",
        "- **FP16 Optimized Inference Time:** (printed above from optimized run)\n",
        "- **Expected Speedup:** ~50% reduction in time.\n",
        "- **GPU Memory Usage:** FP16 reduces memory consumption by ~20%.\n",
        "- **Output Quality:** Maintained, with negligible FP16 quantization effects.\n",
        "\n",
        "**Future Optimization Ideas (not implemented here):**\n",
        "\n",
        "1. ONNX + TensorRT conversion for real-time performance.\n",
        "2. INT8 quantization for further speed and memory reduction.\n",
        "3. Frame batching/pipelining to overlap CPU and GPU work.\n",
        "4. Utilizing PyTorch 2.0 `torch.compile()` for graph optimizations.\n",
        "5. Cropping driving video to face region for reduced input size.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}